{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. OPENCV Face Detection\n",
    "\n",
    "![](../Tutorial/images/salt-pepper.png)\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Content\n",
    "> I. [Frontal Face Detection](#face_detection)\n",
    "II. [Eye Detection](#eye_detection)\n",
    "III. [Smile Detection](#smile_detection)\n",
    "IV. [Face-Eye-Smile Detection](#face_eye_smile_detection)\n",
    "V. [Face Lines Extraction - Charcoal drawing](#charcoal)\n",
    "VI. [Skin Color Detection](#skin)\n",
    "<hr>\n",
    "\n",
    "\n",
    "CascadeClassified filters are one of the most widely used tool for recognizing face and body parts.\n",
    "[Data Link](https://github.com/opencv/opencv/tree/master/data/haarcascades)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='face_detection'> I. Frontal Face Detection </a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "    # load pre-trained classifiers\n",
    "faceCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_frontalface_default.xml'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)       # Capturing default cam\n",
    "while True:\n",
    "    ret, frame = cam.read()     # Read the frame\n",
    "    frame = cv2.flip(frame, 1)   # Use -1 it if cam shows reversely - Use 1 for mirroring\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    # For getting better result, it will be much make sense to give gray scaled frame.\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray_frame,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(20, 20)\n",
    "    )\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height),color= (255, 0, 0), thickness=2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='eye_detection'> II. Eye Detection </a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# load pre-trained classifiers\n",
    "faceCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_frontalface_default.xml'\n",
    ")\n",
    "eyeCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_eye.xml'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)       # Capturing default cam\n",
    "cam.set(3, 1280)    # Width\n",
    "cam.set(4, 720)     # Height\n",
    "filename = 'eye_detection.mp4'\n",
    "recorder = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()     # Read the frame\n",
    "    # frame = cv2.resize(frame, (1280, 720))\n",
    "    frame = cv2.flip(frame, 1)  # Use -1 it if cam shows reversely - Use 1 for mirroring\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray_frame,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(20, 20)\n",
    "    )\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "        face_frame_gray = gray_frame[y:y + height, x:x + width]\n",
    "        face_frame_colored = frame[y:y + height, x:x + width]\n",
    "        eyes = eyeCascade.detectMultiScale(\n",
    "            face_frame_gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(3, 3)\n",
    "        )\n",
    "\n",
    "        for (ex, ey, ewidth, eheight) in eyes:\n",
    "            cv2.rectangle(face_frame_colored, (ex, ey), (ex + ewidth, ey + eheight), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # cv2.imshow('frame', frame)\n",
    "    if recorder is None and filename is not None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mpv4\")    # mp4\n",
    "        recorder = cv2.VideoWriter(filename, fourcc, 25.0, (1280, 720), isColor=True )\n",
    "\n",
    "    if recorder is not None: recorder.write(frame)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "\n",
    "if cam.isOpened():\n",
    "    cam.release()\n",
    "if recorder.isOpened():\n",
    "    recorder.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='smile_detection'> III. Smile Detection </a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load pre-trained classifiers\n",
    "faceCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "smileCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_smile.xml'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 1280)    # Width\n",
    "cam.set(4, 720)     # Height\n",
    "filename = 'smile_detection.mp4'\n",
    "recorder = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)   # Use -1 it if cam shows reversely - Use 1 for mirroring\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray_frame,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "        face_frame_gray = gray_frame[y: y + height, x: x + width]\n",
    "        face_frame_colored = frame[y: y + height, x: x + width]\n",
    "\n",
    "        smiles = smileCascade.detectMultiScale(\n",
    "            face_frame_gray,\n",
    "            scaleFactor=1.5,\n",
    "            minNeighbors=18,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        for (sx, sy, swidth, sheight) in smiles:\n",
    "            cv2.rectangle(face_frame_colored, (sx, sy), (sx + swidth, sy + sheight), (0, 255, 0), 2)\n",
    "            smile_frame_colored = face_frame_colored[sy: sy + height, sx: sx + width]\n",
    "\n",
    "    if recorder is None and filename is not None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")    #.mp4\n",
    "        recorder = cv2.VideoWriter(filename, fourcc, 24.0,\n",
    "                                   (1280, 720), isColor=True)\n",
    "\n",
    "    if recorder is not None: recorder.write(frame)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "\n",
    "if cam.isOpened():\n",
    "    cam.release()\n",
    "if recorder.isOpened():\n",
    "    recorder.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='face_eye_smile_detection'> IV. Face-Eye-Smile Detection </a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load pre-trained classifiers\n",
    "faceCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_frontalface_default.xml'\n",
    ")\n",
    "eyeCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_eye.xml'\n",
    ")\n",
    "smileCascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_smile.xml'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)       # Selecting default cam\n",
    "cam.set(3, 1280)    # Width\n",
    "cam.set(4, 720)     # Height\n",
    "\n",
    "filename='face-eye-smile_detection.mp4'\n",
    "recorder = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1) # Use -1 it if cam shows reversely - Use 1 for mirroring\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray_frame,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(20, 20)\n",
    "    )\n",
    "    for (x, y, width, height) in faces:\n",
    "        # cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "        cv2.circle(frame,(int(x + width / 2), int(y + height / 2)), width//2, (255, 0, 0), 2)\n",
    "        face_frame_gray = gray_frame[y: y + height, x: x + width]\n",
    "        face_frame_colored = frame[y: y + height, x: x + width]\n",
    "\n",
    "        eyes = eyeCascade.detectMultiScale(\n",
    "            face_frame_gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(40, 40)\n",
    "        )\n",
    "        for (ex, ey, ewidth, eheight) in eyes:\n",
    "            cv2.ellipse(face_frame_colored, (int(ex + ewidth / 2), int(ey + eheight / 2)), (ewidth // 2, eheight // 2), 5, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "        smiles = smileCascade.detectMultiScale(\n",
    "            face_frame_gray,\n",
    "            scaleFactor=1.5,\n",
    "            minNeighbors=20,\n",
    "            minSize=(60, 60)\n",
    "        )\n",
    "        for (sx, sy, swidth, sheight) in smiles:\n",
    "            cv2.rectangle(face_frame_colored, (sx, sy), (sx + swidth, sy + sheight), (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if recorder is None and filename is not None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')    # .mp4\n",
    "        recorder = cv2.VideoWriter(filename, fourcc, 24.0, (1280, 720), True)\n",
    "\n",
    "    if recorder is not None: recorder.write(frame)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "\n",
    "if cam.isOpened():\n",
    "    cam.release()\n",
    "if recorder.isOpened():\n",
    "    recorder.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='charcoal'> V. Face Lines Extraction - Charcoal drawing </a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640)\n",
    "cam.set(4, 480)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_frame = cv2.GaussianBlur(gray_frame, (7, 7), 0)\n",
    "    canny = cv2.Canny(blurred_frame, 30, 50)\n",
    "    # If you can use erode and dilate consecutively, it may give better result.\n",
    "    canny = cv2.bitwise_not(canny)\n",
    "    img = cv2.bitwise_and(frame, frame, mask=canny)\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.imshow('canny', canny)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "\n",
    "if cam.isOpened():\n",
    "    cam.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a id='skin'> VI. Skin Color Detection </a>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "YCrCb color space gives much better results in Skin Color Detection. Therefore, we can use it in our script."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,640)  # Width\n",
    "cam.set(4,480)  # Height\n",
    "cam.set(10, 0.8)    # Brightness\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    ycrcb = cv2.inRange(ycrcb, (0, 137, 85), (255, 180, 135))\n",
    "\n",
    "    ycrcb = cv2.morphologyEx(ycrcb, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))   # Use dilate and erode\n",
    "    ycrcb = cv2.dilate(ycrcb, (11, 11), iterations=3)\n",
    "    ycrcb = cv2.erode(ycrcb, (11, 11), iterations=3)\n",
    "    ycrcb = cv2.medianBlur(ycrcb, 5)\n",
    "\n",
    "    result = cv2.bitwise_and(frame, frame, mask=ycrcb)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Mask', ycrcb)\n",
    "    cv2.imshow('Result', result)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27 or key == ord('q'): break\n",
    "\n",
    "if cam.isOpened():\n",
    "    cam.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}